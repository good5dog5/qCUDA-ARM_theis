\chapter{Introduction}
\label{chap:intro}
The deluge of Internet-of-Thing(IoT) create enormous opportunity for machine to recognize the physical
world, the ubiquitous device generate huge size of data at the edge, with the help of deep learning
technique, edge device could extract insight and identify  the surrounding environment. In order to
process these high volume information in real time, processing need to happen near the location
where the data is generated accordingly. However, most of machine learning algorithm and computation device require
significant amount of processing power which may not always be available at the edge.

Autonomous vehicles as one kind of AIoT application have evolved rapidly in the last few
years, which can operate without human control and does
not require any human intervention. As a typical IoT application, self-driving car equipped with
numerous sensor together with GPS and camera. Therefore mutltitple hetergeneous information need to
interpret all together at real time. With leverage on the start-of-art deep learning method 


In this theis, we transport qCUDA, a QEMU + KVM based GPGPU virtualization solution into TX2
development board. qCUDA use API remoting method to submit Nvidia CUDA API from a virtual machine
and bypass it back to host machine to execute the API.The architecture of qCUDA consists of
three parts: library, driver, and virtio virtual device. qCUDA library provide the Nvidia CUDA
interface and analyze the parameter then pass them to qCUDA driver.


%Chapter 4 explains the performance optimization methods developed for the process.